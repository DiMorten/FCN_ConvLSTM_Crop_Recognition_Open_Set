{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiMorten/FCN_ConvLSTM_Crop_Recognition_Open_Set/blob/coords3/train_and_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ7UjI3YD4w8"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJZd_oJYCkmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54da9654-d2f8-42e0-9155-26136991550d"
      },
      "source": [
        "!pip install icecream\n",
        "%tensorflow_version 1.x\n",
        "import os\n",
        "!pip install kora\n",
        "from kora import drive\n",
        "import time\n",
        "!pip install colorama\n",
        "\n",
        "ds_path='/content/drive/My Drive/PhD/datasets/cv_data/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: icecream in /usr/local/lib/python3.7/dist-packages (2.1.1)\n",
            "Requirement already satisfied: colorama>=0.3.9 in /usr/local/lib/python3.7/dist-packages (from icecream) (0.4.4)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.6.1)\n",
            "Requirement already satisfied: executing>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from icecream) (0.7.0)\n",
            "Requirement already satisfied: asttokens>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.0.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
            "TensorFlow 1.x selected.\n",
            "Requirement already satisfied: kora in /usr/local/lib/python3.7/dist-packages (0.9.19)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.7/dist-packages (from kora) (1.3.20)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from kora) (5.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.1.3)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (5.0.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (57.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (1.15.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->kora) (0.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastcore->kora) (2.4.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->kora) (0.7.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cosqh5n5Pewo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "533cb4a4-a51d-43e2-b15c-eb5562d4fd26"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJr_9dXGpJ05",
        "outputId": "15bf2b0c-123a-4255-c35f-fe49a72039f2"
      },
      "source": [
        "git_clone = True\n",
        "\n",
        "if git_clone == True:\n",
        "  os.chdir('/content')\n",
        "  %rm -rf FCN_ConvLSTM_Crop_Recognition_Open_Set\n",
        "  !git clone --branch coords3 https://github.com/DiMorten/FCN_ConvLSTM_Crop_Recognition_Open_Set.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'FCN_ConvLSTM_Crop_Recognition_Open_Set'...\n",
            "remote: Enumerating objects: 1731, done.\u001b[K\n",
            "remote: Counting objects: 100% (1731/1731), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1229/1229), done.\u001b[K\n",
            "remote: Total 1731 (delta 1111), reused 927 (delta 332), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1731/1731), 37.28 MiB | 29.14 MiB/s, done.\n",
            "Resolving deltas: 100% (1111/1111), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdj6CiT0Dz9l"
      },
      "source": [
        "## Download images into proper folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q1eoQFaYvB4",
        "outputId": "4cb2eb7f-0164-44be-fd76-dfbd9c343601",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!cp -r /content/drive/MyDrive/PhD/datasets/lm_data /content/FCN_ConvLSTM_Crop_Recognition_Open_Set/dataset/dataset/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: -r not specified; omitting directory '/content/drive/MyDrive/PhD/datasets/lm_data'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvzH-luqPoiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17022985-1a9c-423e-c4fd-896404dd0b77"
      },
      "source": [
        "os.chdir('/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src')\n",
        "os.getcwd()\n",
        "os.listdir()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['obj',\n",
              " 'deb.py',\n",
              " 'metrics.py',\n",
              " 'model.py',\n",
              " 'keras_weighted_categorical_crossentropy.py',\n",
              " 'dataset.py',\n",
              " 'model_best_UUnet4ConvLSTM_jun_cv_criteria_0_92',\n",
              " 'model_input_mode.py',\n",
              " 'generator.py',\n",
              " 'densnet.py',\n",
              " 'parameters',\n",
              " 'monitor.py',\n",
              " 'densnet_timedistributed.py',\n",
              " 'patch_extractor.py',\n",
              " 'analysis',\n",
              " '__init__.py',\n",
              " 'main.py']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUsDu9hhDZT8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b382ce-3d15-46cb-fb30-cb09c13470b5"
      },
      "source": [
        "from colorama import init\n",
        "init()\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout, Conv2DTranspose\n",
        "# from keras.callbacks import ModelCheckpoint , EarlyStopping\n",
        "from keras.optimizers import Adam,Adagrad \n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "import keras\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras import metrics\n",
        "import sys\n",
        "import glob\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score,classification_report\n",
        "# Local\n",
        "from densnet import DenseNetFCN\n",
        "from densnet_timedistributed import DenseNetFCNTimeDistributed\n",
        "\n",
        "#from metrics import fmeasure,categorical_accuracy\n",
        "import deb\n",
        "from keras_weighted_categorical_crossentropy import weighted_categorical_crossentropy, sparse_accuracy_ignoring_last_label, weighted_categorical_crossentropy_ignoring_last_label, categorical_focal_ignoring_last_label, weighted_categorical_focal_ignoring_last_label\n",
        "from keras.models import load_model\n",
        "from keras.layers import ConvLSTM2D, UpSampling2D, multiply\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.regularizers import l1,l2\n",
        "import time\n",
        "import pickle\n",
        "#from keras_self_attention import SeqSelfAttention\n",
        "import pdb\n",
        "import pathlib\n",
        "from pathlib import Path, PureWindowsPath\n",
        "from keras.layers import Conv3DTranspose, Conv3D\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "#from datagenerator import DataGenerator\n",
        "from generator import DataGenerator, DataGeneratorWithCoords, DataGeneratorWithCoordsPatches\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "sys.path.append('../../../dataset/dataset/patches_extract_script/')\n",
        "from dataSource import DataSource, SARSource, OpticalSource, Dataset, LEM, LEM2, CampoVerde, OpticalSourceWithClouds, Humidity\n",
        "from model_input_mode import MIMFixed, MIMVarLabel, MIMVarSeqLabel, MIMVarLabel_PaddedSeq, MIMFixedLabelAllLabels, MIMFixed_PaddedSeq\n",
        "from parameters.parameters_reader import ParamsTrain\n",
        "\n",
        "from icecream import ic\n",
        "from monitor import Monitor, MonitorNPY, MonitorGenerator, MonitorNPYAndGenerator\n",
        "import natsort\n",
        "from model import NetModel, ModelFit, ModelLoadGenerator, ModelLoadGeneratorDebug, ModelLoadGeneratorWithCoords, ModelLoadEachBatch\n",
        "from dataset import Dataset, DatasetWithCoords\n",
        "\n",
        "from patch_extractor import PatchExtractor\n",
        "ic.configureOutput(includeContext=False)\n",
        "np.random.seed(2021)\n",
        "tf.set_random_seed(2021)\n",
        "\n",
        "from main import TrainTest"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['parameters_openset_specifyunknownclasses.json', 'parameters_openset_lessclass8.json', 'no_mode.json', 'twokkc_parameters_closedset_groupclasses.json', 'twokkc_parameters_openset.json', 'allkkc_parameters_openset.json', 'cv', 'parameters_closedset_groupclasses_lessclass8.json', 'save_nonaugmented_train_patches_lessclass8.json', 'parameters_reader.py', 'parameters_openset.json', '__pycache__', 'parameters_closedset_groupclasses.json', 'twokkc_save_nonaugmented_train_patches.json', 'save_nonaugmented_train_patches_unknownclasses.json', 'allkkc_save_nonaugmented_train_patches.json', 'save_nonaugmented_train_patches.json', '__init__.py']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ic| self.seq_date: 'jun'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self.known_classes [1, 2, 6, 8]\n",
            "[@debug] paramsTrain.seq_mode = fixed\n",
            "[@debug] paramsTrain.mim = <model_input_mode.MIMFixed_PaddedSeq object at 0x7fd7cb6a0d50>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIs_yF23Psa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6467ced0-9ada-42bd-a5dd-837df6dbe383"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jul 20 19:33:05 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On6HSUJwDsCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4116d9f2-76b2-48ec-bed0-bd9297a07668"
      },
      "source": [
        "\n",
        "\n",
        "paramsTrain = ParamsTrain('parameters/')\n",
        "paramsTrain.mim = MIMFixed_PaddedSeq()\n",
        "\n",
        "paramsTrain.dataSource = SARSource()\n",
        "\n",
        "trainTest = TrainTest(paramsTrain)\n",
        "\n",
        "patchExtractor = PatchExtractor(paramsTrain, trainTest.ds)\t\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['parameters_openset_specifyunknownclasses.json', 'parameters_openset_lessclass8.json', 'no_mode.json', 'twokkc_parameters_closedset_groupclasses.json', 'twokkc_parameters_openset.json', 'allkkc_parameters_openset.json', 'cv', 'parameters_closedset_groupclasses_lessclass8.json', 'save_nonaugmented_train_patches_lessclass8.json', 'parameters_reader.py', 'parameters_openset.json', '__pycache__', 'parameters_closedset_groupclasses.json', 'twokkc_save_nonaugmented_train_patches.json', 'save_nonaugmented_train_patches_unknownclasses.json', 'allkkc_save_nonaugmented_train_patches.json', 'save_nonaugmented_train_patches.json', '__init__.py']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ic| self.seq_date: 'jun'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self.known_classes [1, 2, 6, 8]\n",
            "[@debug] self.ds = <dataSource.CampoVerde object at 0x7fd82a298ad0>\n",
            "20151029\n",
            "20151110\n",
            "20151122\n",
            "20151204\n",
            "20151216\n",
            "20160121\n",
            "20160214\n",
            "20160309\n",
            "20160321\n",
            "20160508\n",
            "20160520\n",
            "20160613\n",
            "dotys_sin_cos.shape (12, 2)\n",
            "[302, 314, 326, 338, 350, 21, 45, 69, 81, 129, 141, 165]\n",
            "[[0.05084 0.7197 ]\n",
            " [0.1053  0.807  ]\n",
            " [0.1764  0.8813 ]\n",
            " [0.2612  0.9395 ]\n",
            " [0.3562  0.979  ]\n",
            " [0.6685  0.9707 ]\n",
            " [0.843   0.8643 ]\n",
            " [0.96    0.6963 ]\n",
            " [0.99    0.598  ]\n",
            " [0.905   0.2068 ]\n",
            " [0.8364  0.1301 ]\n",
            " [0.66    0.02637]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ic| self.dataSource: <dataSource.SARSource object at 0x7fd82a298510>\n",
            "ic| self.conf['path']/self.label_folder/\"/\": PosixPath('/')\n",
            "ic| self.conf[\"in_npy_path\"]: PosixPath('../../../dataset/dataset/cv_data/in_sar')\n",
            "ic| self.conf[\"train\"][\"mask\"][\"dir\"]: PosixPath('../../../dataset/dataset/cv_data/TrainTestMask.tif')\n",
            "ic| os.getcwd(): '/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqA-z0Ju9-xO"
      },
      "source": [
        "## Download or load sequence of images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BaFQV6M9yKS",
        "outputId": "81afa771-4d53-4354-d0f5-460ba136d89c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "source": [
        "if paramsTrain.getFullIms == True:\n",
        "  patchExtractor.getFullIms()\t\n",
        "else:\n",
        "  patchExtractor.fullImsLoad()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ic| patch[\"full_ims\"].shape: (12, 8492, 7995, 2)\n",
            "ic| self.dataset.im_list: ['20151029_S1',\n",
            "                           '20151110_S1',\n",
            "                           '20151122_S1',\n",
            "                           '20151204_S1',\n",
            "                           '20151216_S1',\n",
            "                           '20160121_S1',\n",
            "                           '20160214_S1',\n",
            "                           '20160309_S1',\n",
            "                           '20160321_S1',\n",
            "                           '20160508_S1',\n",
            "                           '20160520_S1',\n",
            "                           '20160613_S1']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20151029_S1.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-723faed84226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparamsTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFullIms\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mpatchExtractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFullIms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mpatchExtractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfullImsLoad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src/patch_extractor.py\u001b[0m in \u001b[0;36mgetFullIms\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0madd_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \t\tpatch=self.dataset.im_load(patch,self.dataset.im_list,\n\u001b[0;32m---> 96\u001b[0;31m \t\t\tself.dataset.label_list,add_id,self.conf) # replace patch[full_ims] for self.full_ims\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \t\tpatch[\"full_ims\"] = self.dataSource.clip_undesired_values(\n",
            "\u001b[0;32m/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/dataset/dataset/patches_extract_script/dataSource.py\u001b[0m in \u001b[0;36mim_load\u001b[0;34m(self, patch, im_names, label_names, add_id, conf)\u001b[0m\n\u001b[1;32m    352\u001b[0m                         \u001b[0mdeb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"in_npy_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                         \u001b[0;31m#patch[\"full_ims\"][t_step] = np.load(conf[\"in_npy_path\"]+names[t_step]+\".npy\")[:,:,:2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                         \u001b[0mpatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"full_ims\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_step\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"in_npy_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m                         \u001b[0;31m#patch[\"full_ims\"][t_step] = np.load(conf[\"in_npy_path\"]+names[t_step]+\".npy\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                         \u001b[0mdeb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"full_ims\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/dataset/dataset/patches_extract_script/dataSource.py\u001b[0m in \u001b[0;36mim_load\u001b[0;34m(self, filename, conf)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfull_ims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mim_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../dataset/dataset/cv_data/in_sar/20151029_S1.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5FPmIpS-Hqu"
      },
      "source": [
        "## Extract coords of image patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XzJoNO896wl"
      },
      "source": [
        "\n",
        "if paramsTrain.coordsExtract == True:\n",
        "  patchExtractor.extract()\n",
        "\n",
        "del patchExtractor\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "## Train and evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZztSJXG977M"
      },
      "source": [
        "\n",
        "model_name_id = 'model_best_' + paramsTrain.model_type + '_' + \\\n",
        "    paramsTrain.seq_date + '_' + paramsTrain.dataset + '_' + \\\n",
        "    paramsTrain.model_name + '.h5'\n",
        "\n",
        "if paramsTrain.train == True:\n",
        "  trainTest.trainAndEvaluate(model_name_id)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}